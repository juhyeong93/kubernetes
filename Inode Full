도커 및 쿠버네티스를 운영하다보니 inode가 풀이 나는 경우가 생겼다.

Legacy system의 경우 보통 Inode를 늘려주거나 additional disk를 붙혀주어 disk size를 늘리는 방법등이 있으나
google이 managed 하는 Saas 방식의 kubernetes는 디스크를 늘려주거나 Inode를 늘려주는 방법이 없다고 google caseopen을 통하여 전달 받음.

각 Running 중인 node (Compute Ecgine)에서 df -i 를 통해 inode 사용량을 확인하여 full찬 노드들에 대하여 아래와 같은 방법 수행
방법은 세가지가 있다. 
1. 수동으로 디크스내의 docker 이미지 파일을 지우기
2. 새로운 노드를 만들어서 마이그레이션.
3. 기존 사이즈 보다 더 큰 노드를 만들어 마이그레이션
 -3번 같은경우도 임시솔루션에 불과 -> 아무리 디스크를 큰 노드를 만든다해도 지속적으로 쌓이는 이미지들을 정리 하지 않는다면 언젠간 full 찰 가능성
 
 
2번을 선택하여 임시 조치를 진행하였음 
새로운 노드가 생성이 되면 VM 즉 노드가 새로 생성 되는것이기 때문에 Inode도 1%부터 새로 생성됨.
작업 절차

#kubectl cordon <node_ID> 
      - Inode 이슈가 있는 node를 scheduling 하지 않도록 cordon을 시켜쥼

#gcloud container clusters resize one-devops-ci --node-pool n2-pool-2 --num-nodes 2 --region asia-southeast1
     - 문제가 있는 노드를 scheduling되지 않도록 한 후 cluster의 사이즈를 늘려줌.
     - 이때 vm 생성이 오래걸린다면 ip부족을 의심해 볼수 있음. 구글의 개발 프로세스겠지만 error로 return 하지는않고  다만 시간이 좀 오래걸림.

kubectl drain <node_ID> --force --ignore-daemonsets --delete-emptydir-data --grace-period=10 
     - 문제의 노드에서 실행되는 Pod들을 다른 노드로 옮기는 작업.
     - 새로 생성된 노드로 Pod들이 scheduling 됨
     
gcloud container clusters resize one-devops-ci --node-pool n2-pool-2 --num-nodes 1 --region asia-southeast1
     - drain으로 Pod들을 모두 옮겼다면 다시 cluster의 node들을 1개로 리사이징 해준다면 완료.
     - 새로 생긴 노드는 Inode가 0%부터 시작되는것을 알 수 있고 문제가 없던 node들은 기존 그대로 유지.(리사이즈가 된것들이 다시 없어짐)
     
     
